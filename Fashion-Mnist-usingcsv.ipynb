{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from torch.utils.data import DataLoader, random_split\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#path of the respective csv files\r\n",
    "\r\n",
    "training_data_path = r'D:\\Coding\\Python Programming\\Modules\\Pytorch\\csvs\\fashion-mnist_train.csv'\r\n",
    "test_data_path = r'D:\\Coding\\Python Programming\\Modules\\Pytorch\\csvs\\fashion-mnist_test.csv'\r\n",
    "\r\n",
    "#loading the csv files uning pandas\r\n",
    "\r\n",
    "training_data = pd.read_csv(training_data_path)\r\n",
    "test_data = pd.read_csv(test_data_path)\r\n",
    "\r\n",
    "#converting them into numpy array\r\n",
    "\r\n",
    "training_data = np.array(training_data)\r\n",
    "test_data = np.array(test_data)\r\n",
    "\r\n",
    "#converting them into torch(we cant convert the initial training_data directly to tensors as they are a dataframe object)\r\n",
    "\r\n",
    "training_data = torch.from_numpy(training_data)\r\n",
    "test_data = torch.from_numpy(test_data)\r\n",
    "\r\n",
    "training_data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#spliting the training data into training and validation data\r\n",
    "train_data, validation_data = random_split(training_data, [50000,10000])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Creating Batches for training\r\n",
    "batch_size = 128\r\n",
    "train_dl = DataLoader(train_data, batch_size = batch_size, shuffle = True)\r\n",
    "valid_dl = DataLoader(validation_data, batch_size= batch_size, shuffle= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Now the values of the inputs in the csv file are between (0,255) so we need to scale the inputs and for that we will divide the input valiables by 255\r\n",
    "#creating the model\r\n",
    "class FashionModel(torch.nn.Module):\r\n",
    "    def __init__(self, input_size, layer_size, output_size):\r\n",
    "        super().__init__()\r\n",
    "        self.linear1 = torch.nn.Linear(input_size, layer_size)\r\n",
    "        self.linear2 = torch.nn.Linear(layer_size, output_size)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        x = x/255\r\n",
    "        out = self.linear1(x)\r\n",
    "        out = torch.relu(out)\r\n",
    "        out = self.linear2(out)\r\n",
    "        out = torch.softmax(out, dim = 0)\r\n",
    "        return out\r\n",
    "\r\n",
    "input_size = 784\r\n",
    "layer_size = 64\r\n",
    "output_size = 10\r\n",
    "model = FashionModel(input_size, layer_size, output_size)   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "targets = training_data[:,0]\r\n",
    "targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#making training loop\r\n",
    "\r\n",
    "loss_fn = torch.nn.BCELoss()\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.02)\r\n",
    "\r\n",
    "epochs = 5\r\n",
    "\r\n",
    "for epoch in tqdm(range(epochs)):\r\n",
    "    for i in train_dl:\r\n",
    "        input_data = i[:,1:785]\r\n",
    "        label_arr = i[:,0]\r\n",
    "        label = []\r\n",
    "        for _ in label_arr:\r\n",
    "            var = np.zeros(10)\r\n",
    "            var[int(_)] = 1\r\n",
    "            label.append(var.astype(np.float32))\r\n",
    "        label = torch.tensor(label)\r\n",
    "        \r\n",
    "        preds = model(input_data)\r\n",
    "        loss = loss_fn(preds, label)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        optimizer.zero_grad()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Checking the accuracy with the data from Validation Set(valid_dl) And mapping the image using matplotlib\r\n",
    "with torch.no_grad():\r\n",
    "    for i in valid_dl:\r\n",
    "        input_validation = i[:,1:785]\r\n",
    "        label = i[:,0]\r\n",
    "        preds = model(input_validation)\r\n",
    "    preds_arr = torch.argmax(preds,1)\r\n",
    "    accuracy = torch.sum(preds_arr == label).item()/len(preds_arr)\r\n",
    "print(accuracy)\r\n",
    "i = 3\r\n",
    "print(\"Prediction: {}, Label: {}\".format(preds_arr[i], label[i]))\r\n",
    "plt.imshow(input_validation[i].reshape(28,28), cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.75\n",
      "Prediction: 0, Label: 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "execution_count": 66
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}