{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Grandient Descent using NumPy\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# f = w*x\r\n",
    "# f = 2*x\r\n",
    "\r\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\r\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\r\n",
    "\r\n",
    "w = 0.0\r\n",
    "\r\n",
    "#forwardpass\r\n",
    "def forward(x):\r\n",
    "    return w * x\r\n",
    "\r\n",
    "#loss = MSE\r\n",
    "def loss(y, y_predicted):\r\n",
    "    return ((y_predicted - y) ** 2).mean()\r\n",
    "\r\n",
    "#gradient\r\n",
    "#MSE = 1/N * (w*x - y)**2\r\n",
    "#dJ/dw = 1/N * 2x(w*x - y)\r\n",
    "def gradient(x,y,y_predicted):\r\n",
    "    return np.dot(2*x, y_predicted - y).mean()\r\n",
    "\r\n",
    "print(forward(5))\r\n",
    "\r\n",
    "#training\r\n",
    "learning_rate = 0.01\r\n",
    "n_iters = 20\r\n",
    "\r\n",
    "for epoch in range(n_iters):\r\n",
    "    y_pred = forward(X)\r\n",
    "    \r\n",
    "    l = loss(Y, y_pred)\r\n",
    "    \r\n",
    "    dw = gradient(X,Y,y_pred)\r\n",
    "    \r\n",
    "    w -= learning_rate * dw\r\n",
    "print(forward(5))\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n",
      "9.999999976158142\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch \r\n",
    "\r\n",
    "# f = w*x\r\n",
    "# f = 2*x\r\n",
    "\r\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\r\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\r\n",
    "\r\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad= True)\r\n",
    "\r\n",
    "#forwardpass\r\n",
    "def forward(x):\r\n",
    "    return w * x\r\n",
    "\r\n",
    "#loss = MSE\r\n",
    "def loss(y, y_predicted):\r\n",
    "    return ((y_predicted - y) ** 2).mean()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(forward(5))\r\n",
    "\r\n",
    "#training\r\n",
    "learning_rate = 0.01\r\n",
    "n_iters = 76\r\n",
    "\r\n",
    "for epoch in range(n_iters):\r\n",
    "    y_pred = forward(X)\r\n",
    "    \r\n",
    "    l = loss(Y, y_pred)\r\n",
    "    \r\n",
    "    #gradient = backwardpass\r\n",
    "    l.backward()\r\n",
    "    with torch.no_grad():\r\n",
    "        w -= learning_rate * w.grad\r\n",
    "    w.grad.zero_()\r\n",
    "    \r\n",
    "print(forward(5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#trainig pipeline tutorial\r\n",
    "# 1) training model(input, output size, forwardpass)\r\n",
    "# 2) construct loss and optimizer\r\n",
    "# 3) trainig pipeline\r\n",
    "# - forwardpass - compute prediction\r\n",
    "# - backwardpass - gradient\r\n",
    "# - update weights\r\n",
    "\r\n",
    "import torch\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype= torch.float32)\r\n",
    "\r\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype= torch.float32)\r\n",
    "\r\n",
    "X_test = torch.tensor([5], dtype= torch.float32)\r\n",
    "\r\n",
    "n_sample, n_features = X.shape\r\n",
    "\r\n",
    "print(n_sample, n_features)\r\n",
    "\r\n",
    "input_size = n_features\r\n",
    "output_size = n_features\r\n",
    "\r\n",
    "model = nn.Linear(input_size , output_size)\r\n",
    "\r\n",
    "print(model(X_test).item())\r\n",
    "\r\n",
    "learning_rate = 0.01\r\n",
    "\r\n",
    "n_iters = 500\r\n",
    "\r\n",
    "loss = nn.MSELoss()\r\n",
    "\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\r\n",
    "\r\n",
    "for epoch in range(n_iters):\r\n",
    "    y_pred = model(X)\r\n",
    "    \r\n",
    "    l = loss(Y, y_pred)\r\n",
    "    \r\n",
    "    l.backward()\r\n",
    "    \r\n",
    "    optimizer.step()\r\n",
    "    \r\n",
    "    optimizer.zero_grad()\r\n",
    "\r\n",
    "print(model(X_test).item())\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1) making model(input,output size, forwardpass)\r\n",
    "# 2) Construct training loop and optimizer\r\n",
    "# 3) Training Loop\r\n",
    "# - forward pass : compute prediction and loss\r\n",
    "# - backward pass : Gradient\r\n",
    "# - update weights\r\n",
    "import torch\r\n",
    "import numpy as np\r\n",
    "import torch.nn as nn\r\n",
    "from sklearn import datasets\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# 0) prepare data\r\n",
    "x_numpy , y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise = 20, random_state = 1)\r\n",
    "\r\n",
    "X = torch.from_numpy(x_numpy.astype(np.float32))\r\n",
    "Y = torch.from_numpy(y_numpy.astype(np.float32))\r\n",
    "\r\n",
    "Y = Y.view(Y.shape[0], 1)\r\n",
    "\r\n",
    "n_sample, n_features = X.shape\r\n",
    "\r\n",
    "# 1) model\r\n",
    "\r\n",
    "input_size = n_features\r\n",
    "output_size = 1\r\n",
    "model = nn.Linear(input_size, output_size)\r\n",
    "\r\n",
    "\r\n",
    "# 2) loss and optimizer\r\n",
    "\r\n",
    "learning_rate = 0.1\r\n",
    "criterion = nn.MSELoss()\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    "# 3) training loop  \r\n",
    "\r\n",
    "num_iters = 100\r\n",
    "\r\n",
    "for epochs in range(num_iters):\r\n",
    "    y_predicted = model(X)\r\n",
    "    loss = criterion(y_predicted, Y)\r\n",
    "    \r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "    \r\n",
    "    optimizer.zero_grad()\r\n",
    "    \r\n",
    "predicted = model(X).detach().numpy()\r\n",
    "\r\n",
    "plt.plot(x_numpy , y_numpy, 'ro')\r\n",
    "plt.plot(x_numpy, predicted, 'b')\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}