{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "from torchvision.datasets import MNIST\r\n",
    "import numpy as np\r\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset = MNIST(root = 'data/', download = True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "len(dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "image, label = dataset[0]\r\n",
    "plt.imshow(image, cmap = 'gray')\r\n",
    "print(label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dataset = MNIST(root = 'data/', train = True, transform= transforms.ToTensor())\r\n",
    "test_dataset = MNIST(root = 'data/', train = False, transform= transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "img_tensor, label = dataset[0]\r\n",
    "print(img_tensor.shape, label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(img_tensor[:, 10:15,10:15])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "plt.imshow(img_tensor[0,10:15,10:15], cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c1f770e640>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from torch.utils.data import random_split\r\n",
    "\r\n",
    "train_ds , valid_ds = random_split(dataset, [50000,10000])\r\n",
    "\r\n",
    "len(train_ds), len(valid_ds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "batch_size = 128\r\n",
    "\r\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle= True)\r\n",
    "valid_dl = DataLoader(valid_ds, batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import torch.nn as nn\r\n",
    "\r\n",
    "input_size = 28*28\r\n",
    "num_classes = 10\r\n",
    "\r\n",
    "model = nn.Linear(input_size, num_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(model.weight.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(model.bias.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "for image, label in train_dl:\r\n",
    "    print(label)\r\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([8, 5, 6, 7, 3, 5, 2, 9, 3, 3, 7, 5, 6, 6, 4, 5, 6, 8, 9, 0, 3, 8, 4, 0,\n",
      "        5, 3, 2, 7, 4, 6, 4, 2, 0, 0, 4, 7, 0, 3, 7, 2, 3, 5, 5, 4, 8, 6, 3, 9,\n",
      "        2, 4, 2, 7, 5, 6, 6, 2, 8, 1, 8, 4, 5, 7, 1, 1, 5, 3, 0, 2, 5, 2, 9, 7,\n",
      "        0, 5, 1, 0, 5, 5, 1, 0, 0, 8, 7, 8, 4, 1, 9, 2, 4, 1, 6, 8, 3, 6, 3, 4,\n",
      "        5, 8, 1, 1, 0, 1, 1, 8, 7, 8, 5, 7, 1, 2, 0, 8, 2, 5, 4, 6, 6, 3, 1, 3,\n",
      "        6, 4, 4, 6, 5, 4, 3, 6])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "image.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "image.reshape(128,784).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "class MnistModel(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(input_size, num_classes)\r\n",
    "    \r\n",
    "    def forward(self,xb):\r\n",
    "        xb = xb.reshape(-1, 784)\r\n",
    "        out = self.linear(xb)\r\n",
    "        return out\r\n",
    "\r\n",
    "model = MnistModel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for images, labels in train_dl:\r\n",
    "    print(images.shape)\r\n",
    "    output = model(images)\r\n",
    "    break\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import torch.nn.functional as F    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "probs = F.softmax(output, dim=1)\r\n",
    "\r\n",
    "max_probs, preds = torch.max(probs, dim=1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def accuracy(outputs,labels):\r\n",
    "    _, preds = torch.max(outputs, dim = 1)\r\n",
    "    return torch.tensor(torch.sum(preds == labels).item()/ len(preds))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "accuracy(output, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.1406)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "loss_fn = F.cross_entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "loss = loss_fn(output, labels)\r\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2.3338, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def fit(epochs, lr, model, train_dl, valid_dl, opt_func = torch.optim.SGD):\r\n",
    "    optimizer = opt_func(model.parameters(), lr)\r\n",
    "    history = []\r\n",
    "    \r\n",
    "    for epoch in range(epochs):\r\n",
    "        for batch in train_dl:\r\n",
    "            loss = model.training_step(batch)\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.zero_grad()\r\n",
    "            \r\n",
    "        result = evaluate(model, valid_dl)\r\n",
    "        model.epoch_end(epoch, result)\r\n",
    "        history.append(result)\r\n",
    "    return history\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def evaluate(model, val_loader):\r\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\r\n",
    "    return model.validation_epoch_end(outputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "class MnistModel(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(input_size, num_classes)\r\n",
    "    \r\n",
    "    def forward(self, xb):\r\n",
    "        xb = xb.reshape(-1, 784)\r\n",
    "        out = self.linear(xb)\r\n",
    "        return out\r\n",
    "    \r\n",
    "    def training_step(self, batch):\r\n",
    "        images, labels = batch\r\n",
    "        out = self(images)\r\n",
    "        loss = F.cross_entropy(out, labels)\r\n",
    "        return loss\r\n",
    "    \r\n",
    "    def validation_step(self,batch):\r\n",
    "        images, labels = batch\r\n",
    "        out = self(images)\r\n",
    "        loss = F.cross_entropy(out, labels)\r\n",
    "        acc = accuracy(out, labels)\r\n",
    "        return {'val_loss': loss, 'val_acc' : acc}\r\n",
    "    \r\n",
    "    def weights(self):\r\n",
    "        return self.linear.weight\r\n",
    "    \r\n",
    "    def bias(self):\r\n",
    "        return self.linear.bias\r\n",
    "    \r\n",
    "    def validation_epoch_end(self, output):\r\n",
    "        batch_losses = [x['val_loss'] for x in output]\r\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\r\n",
    "        batch_accs = [x['val_acc'] for x in output]\r\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\r\n",
    "        \r\n",
    "        return {'val_loss': epoch_loss, 'val_acc': epoch_acc}\r\n",
    "    \r\n",
    "    def epoch_end(self, epoch, result):\r\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch+1, result['val_loss'], result['val_acc']))\r\n",
    "\r\n",
    "model = MnistModel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "history1 = fit(10, 0.001, model, train_dl, valid_dl)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1], val_loss: 1.9511, val_acc: 0.6021\n",
      "Epoch [2], val_loss: 1.6821, val_acc: 0.7236\n",
      "Epoch [3], val_loss: 1.4803, val_acc: 0.7683\n",
      "Epoch [4], val_loss: 1.3275, val_acc: 0.7908\n",
      "Epoch [5], val_loss: 1.2098, val_acc: 0.8027\n",
      "Epoch [6], val_loss: 1.1170, val_acc: 0.8114\n",
      "Epoch [7], val_loss: 1.0426, val_acc: 0.8191\n",
      "Epoch [8], val_loss: 0.9816, val_acc: 0.8253\n",
      "Epoch [9], val_loss: 0.9308, val_acc: 0.8293\n",
      "Epoch [10], val_loss: 0.8878, val_acc: 0.8339\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "history2 = fit(10, 0.01, model, train_dl, valid_dl)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1], val_loss: 0.6630, val_acc: 0.8582\n",
      "Epoch [2], val_loss: 0.5709, val_acc: 0.8687\n",
      "Epoch [3], val_loss: 0.5190, val_acc: 0.8761\n",
      "Epoch [4], val_loss: 0.4852, val_acc: 0.8807\n",
      "Epoch [5], val_loss: 0.4607, val_acc: 0.8839\n",
      "Epoch [6], val_loss: 0.4423, val_acc: 0.8864\n",
      "Epoch [7], val_loss: 0.4278, val_acc: 0.8893\n",
      "Epoch [8], val_loss: 0.4159, val_acc: 0.8912\n",
      "Epoch [9], val_loss: 0.4059, val_acc: 0.8926\n",
      "Epoch [10], val_loss: 0.3975, val_acc: 0.8939\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "weights, bias=list(model.parameters())\r\n",
    "weights = weights[0]\r\n",
    "size = (300,300)\r\n",
    "with torch.no_grad():\r\n",
    "    weights = weights.numpy()\r\n",
    "    weights = np.reshape(weights, [28,28])\r\n",
    "    img = Image.fromarray(weights * 255)\r\n",
    "    img.resize(size)\r\n",
    "    img.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def predict_image(img, model):\r\n",
    "    xb = img.unsqueeze(0)\r\n",
    "    yb = model(xb)\r\n",
    "    _, preds = torch.max(yb, dim = 1)\r\n",
    "    return preds[0].item()\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "img, label = test_dataset[321]\r\n",
    "plt.imshow(img[0], cmap = 'gray')\r\n",
    "print('Label: ', label,'Prediction: ', predict_image(img, model))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label:  7 Prediction:  7\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}